# TICKETS

# üõ°Ô∏è App Market Sentinel

> **Intelligent SaaS & App Store Analytics Platform**
> 
> 
> *Data Engineering Pipeline & Market Intelligence Engine*
> 

## 1. Visi√≥n del Proyecto

**App Market Sentinel** es un sistema de ingenier√≠a de datos de alto rendimiento dise√±ado para la ingesta, normalizaci√≥n y an√°lisis de inteligencia competitiva en tiendas de aplicaciones y plataformas SaaS.

A diferencia de un scraper tradicional, este sistema implementa una arquitectura orientada a eventos, capaz de manejar series temporales de precios (Financial Data) y grandes vol√∫menes de texto no estructurado (Reviews/Changelogs), preparando la infraestructura de datos para modelos de **Inteligencia Artificial (RAG)**.

### üéØ Objetivos T√©cnicos (Fase 1)

1. **Ingesta As√≠ncrona:** Crawling concurrente de alta eficiencia sin bloqueos (Non-blocking I/O).
2. **Integridad de Datos:** Normalizaci√≥n estricta de fuentes heterog√©neas (App Store vs Play Store) usando validaci√≥n de esquemas.
3. **Advanced SQL:** Uso de particionamiento, √≠ndices GIN para JSONB y Vistas Materializadas en PostgreSQL.
4. **AI-Readiness:** Limpieza y segmentaci√≥n de texto (Chunking) lista para vectorizaci√≥n.

---

## 2. Arquitectura del Sistema

El sistema sigue un patr√≥n de **Modular Monolith** con separaci√≥n estricta entre la API (lectura/gesti√≥n) y los Workers (escritura/procesamiento pesado).

### Diagrama de Contenedores

Fragmento de c√≥digo

`graph TD
    User((Cliente)) -->|REST API| API[FastAPI Backend]
    API -->|Read/Write| DB[(PostgreSQL 16)]
    API -->|Dispatch Jobs| Redis[(Redis Queue)]
    
    Worker[Worker Async - Arq] -->|Consume Jobs| Redis
    Worker -->|Scraping (Httpx)| Web((Fuentes Externas))
    Worker -->|Batch Processing (Polars)| DB
    
    DB -.->|Store Embeddings| PgVector`

### Componentes Core

| **Componente** | **Tecnolog√≠a** | **Responsabilidad** |
| --- | --- | --- |
| **API Server** | FastAPI + Uvicorn | Endpoints REST, validaci√≥n de entrada, gesti√≥n de usuarios. |
| **Ingestion Engine** | Python Asyncio + Httpx | Scraping concurrente, rotaci√≥n de proxies, manejo de retries. |
| **Data Processor** | Polars (Rust-backed) | Limpieza de texto masiva, normalizaci√≥n de precios, detecci√≥n de PII. |
| **Task Queue** | Arq + Redis | Orquestaci√≥n de trabajos en background. |
| **Storage** | PostgreSQL 16 | Almacenamiento relacional (Precios), Documental (Reviews JSONB) y Vectorial. |

---

## 3. Stack Tecnol√≥gico & Decisiones (ADR)

Selecci√≥n de herramientas basada en performance, tipado estricto y seguridad.

- **Lenguaje:** `Python 3.12+` (Tipado fuerte, features modernas de Asyncio).
- **Web Framework:** `FastAPI` (Est√°ndar de industria para Data APIs).
- **Database:** `PostgreSQL 16` + `pgvector`.
    - *Decisi√≥n:* Uso de **JSONB** para flexibilidad en metadatos de reviews y **Partitioning** para el hist√≥rico de precios (Time-Series).
- **ORM:** `SQLAlchemy 2.0 (Async)`. Patr√≥n Repository para abstracci√≥n de datos.
- **Validaci√≥n:** `Pydantic v2`. Validaci√≥n de esquemas en tiempo de ejecuci√≥n (Rust core).
- **Gesti√≥n de Entorno:** `Docker Compose` + `Poetry` (Dependency locking).
- **Testing:** `Pytest` + `Testcontainers` (Pruebas de integraci√≥n reales).

---

## 4. Modelo de Datos (Schema Design)

El esquema est√° optimizado para consultas anal√≠ticas y b√∫squeda de texto.

### Tablas Principales

1. **`apps` (Master Data):**
    - `id` (UUID), `bundle_id`, `platform` (Enum), `developer_id`.
2. **`price_history` (Time-Series):**
    - *Particionada por rango de fecha (Mensual).*
    - `app_id`, `price` (Decimal), `currency`, `timestamp` (BRIN Index).
3. **`reviews` (Unstructured Data):**
    - `app_id`, `rating`, `content` (Text), `metadata` (JSONB).
    - *√çndice:* **GIN** sobre `metadata` para b√∫squedas r√°pidas (ej: versi√≥n del dispositivo).
    - *Vector:* Columna `embedding` (vector(1536)) preparada para Fase 2.

---

## 5. Roadmap de Implementaci√≥n (Backlog Fase 1)

Plan de trabajo de 6 semanas dividido en Sprints l√≥gicos.

### üìÖ Semanas 1-2: Fundamentos y Modelado

### üé´ Ticket 1: Setup de Infraestructura As√≠ncrona & Docker

- **Objetivo:** Entorno reproducible con Docker Compose.
- **Tareas:**
    - [ ]  Configurar `docker-compose.yml` (Postgres 16, Redis, App).
    - [ ]  Setup de Poetry y Pydantic Settings.
    - [ ]  Configurar Linter (Ruff) y Pre-commit hooks.
- **DoD:** `docker-compose up` levanta sin errores.

### üé´ Ticket 2: Modelado de DB Avanzado

- **Objetivo:** Esquema SQL resiliente.
- **Tareas:**
    - [ ]  Configurar Alembic Async.
    - [ ]  Implementar Tabla Particionada `price_history`.
    - [ ]  Implementar Tabla `reviews` con JSONB e √≠ndices GIN.
- **DoD:** Migraciones aplicadas y verificaci√≥n de particiones en DB.

### üìÖ Semanas 3-4: Ingesta y L√≥gica

### üé´ Ticket 3: Motor de Ingesta (Scraper Core)

- **Objetivo:** Worker as√≠ncrono robusto.
- **Tareas:**
    - [ ]  Cliente `httpx` con rotaci√≥n de User-Agents.
    - [ ]  L√≥gica de Retries con `tenacity`.
    - [ ]  Parsers de HTML con `BeautifulSoup` para extraer precios y textos.
- **DoD:** Scraping exitoso de 50 URLs concurrentes manejando errores 429.

### üé´ Ticket 4: Validaci√≥n & Integridad

- **Objetivo:** Data Quality Firewall.
- **Tareas:**
    - [ ]  Schemas Pydantic v2 para entrada de datos sucios.
    - [ ]  Normalizaci√≥n de monedas y formatos de fecha.
- **DoD:** Tests unitarios fallan ante datos inv√°lidos.

### üé´ Ticket 5: Procesamiento de Texto con Polars

- **Objetivo:** Preparaci√≥n para IA (Data Cleaning).
- **Tareas:**
    - [ ]  Pipeline en Polars para limpieza de texto (regex, lowercasing).
    - [ ]  Anonimizaci√≥n de PII b√°sica en reviews.
- **DoD:** Procesamiento de 10k reviews en < 1 segundo.

### üìÖ Semanas 5-6: API & Despliegue

### üé´ Ticket 6: API RESTful High-Performance

- **Objetivo:** Exponer datos al mundo.
- **Tareas:**
    - [ ]  Endpoints FastAPI (`GET /apps`, `GET /history`).
    - [ ]  Implementar Paginaci√≥n (Cursor-based).
    - [ ]  Documentaci√≥n OpenAPI (Swagger).
- **DoD:** Response time < 200ms en local.

### üé´ Ticket 7: Optimizaci√≥n SQL & Vistas Materializadas

- **Objetivo:** Analytics en tiempo real.
- **Tareas:**
    - [ ]  Crear Materialized View para tendencias de precios.
    - [ ]  Optimizar queries con `EXPLAIN ANALYZE`.
- **DoD:** Reducci√≥n de tiempo de query compleja en un 50%.

### üé´ Ticket 8: Observabilidad & Logs

- **Objetivo:** Trazabilidad nivel Lead.
- **Tareas:**
    - [ ]  Implementar `structlog` (JSON logs).
    - [ ]  A√±adir Correlation IDs en requests.
- **DoD:** Logs trazables desde API hasta Worker.

### üé´ Ticket 9: Hardening & Docker Prod

- **Objetivo:** Seguridad de Contenedores.
- **Tareas:**
    - [ ]  Usuario non-root en Dockerfile.
    - [ ]  Escaneo de vulnerabilidades con Trivy.
- **DoD:** Imagen limpia de vulnerabilidades cr√≠ticas.

---

## 6. Estructura del Repositorio

Plaintext

`app-market-sentinel/
‚îú‚îÄ‚îÄ .github/workflows/    # CI/CD (Tests, Linting)
‚îú‚îÄ‚îÄ docker/               # Configuraci√≥n de contenedores
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/              # FastAPI Application
‚îÇ   ‚îú‚îÄ‚îÄ core/             # Configuraci√≥n, DB Session, Logging
‚îÇ   ‚îú‚îÄ‚îÄ modules/          # Dominios (Apps, Scraping, Analytics)
‚îÇ   ‚îî‚îÄ‚îÄ worker/           # Background Workers (Arq)
‚îú‚îÄ‚îÄ tests/                # Pytest (Unit & Integration)
‚îú‚îÄ‚îÄ alembic/              # Migraciones de DB
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ pyproject.toml        # Dependencias
‚îî‚îÄ‚îÄ README.md             # Este documento`
